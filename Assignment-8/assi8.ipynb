{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab929adf",
   "metadata": {},
   "source": [
    "ques 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd420eda",
   "metadata": {},
   "source": [
    "part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f113e62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "df = pd.read_csv(\"spam.csv\", encoding=\"latin-1\")[[\"v1\",\"v2\"]]\n",
    "df.columns = [\"label\",\"text\"]\n",
    "\n",
    "df[\"label\"] = df[\"label\"].map({\"ham\":0, \"spam\":1})\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = \"\".join([c for c in text if c not in string.punctuation])\n",
    "    text = \" \".join([w for w in text.split() if w not in stop_words])\n",
    "    return text\n",
    "\n",
    "df[\"clean_text\"] = df[\"text\"].apply(preprocess)\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(df[\"clean_text\"])\n",
    "y = df[\"label\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42\n",
    ")\n",
    "\n",
    "print(df[\"label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6be705",
   "metadata": {},
   "source": [
    "part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f601a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stump = DecisionTreeClassifier(max_depth=1)\n",
    "stump.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = stump.predict(X_train)\n",
    "y_pred_test = stump.predict(X_test)\n",
    "\n",
    "print(\"Train Accuracy:\", accuracy_score(y_train, y_pred_train))\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37ef6cd",
   "metadata": {},
   "source": [
    "part c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cbf476",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "\n",
    "T = 15\n",
    "n = X_train.shape[0]\n",
    "weights = np.ones(n) / n\n",
    "\n",
    "alphas = []\n",
    "errors = []\n",
    "misclassified_history = []\n",
    "\n",
    "for t in range(T):\n",
    "\n",
    "    stump = DecisionTreeClassifier(max_depth=1)\n",
    "    stump.fit(X_train, y_train, sample_weight=weights)\n",
    "    y_pred = stump.predict(X_train)\n",
    "\n",
    "    err = np.sum(weights * (y_pred != y_train)) / np.sum(weights)\n",
    "    errors.append(err)\n",
    "\n",
    "    alpha = 0.5 * np.log((1 - err) / (err + 1e-10))\n",
    "    alphas.append(alpha)\n",
    "\n",
    "    misclassified_idx = np.where(y_pred != y_train)[0]\n",
    "    misclassified_history.append(misclassified_idx)\n",
    "\n",
    "    print(f\"\\nIteration {t+1}\")\n",
    "    print(\"Misclassified samples:\", misclassified_idx[:10], \"...\") \n",
    "    print(\"Weights of misclassified:\", weights[misclassified_idx][:10])\n",
    "    print(\"Alpha:\", alpha)\n",
    "\n",
    "    weights = weights * np.exp(alpha * (y_pred != y_train))\n",
    "    weights = weights / np.sum(weights)   \n",
    "\n",
    "def ada_predict(X):\n",
    "    final = np.zeros(X.shape[0])\n",
    "    for alpha, stump in zip(alphas, [DecisionTreeClassifier(max_depth=1).fit(\n",
    "            X_train, y_train, sample_weight=weights) for _ in range(T)]):\n",
    "        final += alpha * stump.predict(X)\n",
    "    return np.sign(final)\n",
    "\n",
    "y_test_pred = ada_predict(X_test)\n",
    "\n",
    "print(\"\\nFinal Train Accuracy:\", accuracy_score(y_train, ada_predict(X_train)))\n",
    "print(\"Final Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd80dcc",
   "metadata": {},
   "source": [
    "part d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfd1dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.6\n",
    ")\n",
    "\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ada.predict(X_test)\n",
    "\n",
    "print(\"Train Accuracy:\", accuracy_score(y_train, ada.predict(X_train)))\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee324b29",
   "metadata": {},
   "source": [
    "ques 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67432ee",
   "metadata": {},
   "source": [
    "part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcccade",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_heart_disease   \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "data = load_heart_disease()  \n",
    "\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "stump = DecisionTreeClassifier(max_depth=1)\n",
    "stump.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train Acc:\", stump.score(X_train, y_train))\n",
    "print(\"Test Acc:\", stump.score(X_test, y_test))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, stump.predict(X_test)))\n",
    "print(classification_report(y_test, stump.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d868dc",
   "metadata": {},
   "source": [
    "part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a262e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "estimators = [5, 10, 25, 50, 100]\n",
    "rates = [0.1, 0.5, 1.0]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for lr in rates:\n",
    "    results[lr] = []\n",
    "    for n in estimators:\n",
    "        model = AdaBoostClassifier(\n",
    "            estimator=DecisionTreeClassifier(max_depth=1),\n",
    "            n_estimators=n, learning_rate=lr\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "        acc = model.score(X_test, y_test)\n",
    "        results[lr].append(acc)\n",
    "        print(lr, n, acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2a8d98",
   "metadata": {},
   "source": [
    "part c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a338ed00",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = model.estimator_errors_\n",
    "weights = model.estimator_weights_\n",
    "\n",
    "plt.plot(errors)\n",
    "plt.title(\"Weak Learner Error vs Iteration\")\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(weights)\n",
    "plt.title(\"Final Weight Distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d03e8f",
   "metadata": {},
   "source": [
    "part d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3455f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model.feature_importances_\n",
    "idx = np.argsort(importances)[::-1]\n",
    "\n",
    "top5 = idx[:5]\n",
    "for i in top5:\n",
    "    print(data.feature_names[i], importances[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bd2959",
   "metadata": {},
   "source": [
    "ques 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b748c02",
   "metadata": {},
   "source": [
    "part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3256a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"WISDM_ar_v1.1_raw.txt\", header=None, sep=\",\")\n",
    "df = df.dropna()\n",
    "\n",
    "df.columns = [\"user\",\"activity\",\"timestamp\",\"x\",\"y\",\"z\"]\n",
    "\n",
    "df[\"label\"] = df[\"activity\"].apply(\n",
    "    lambda a: 1 if a.lower() in [\"jogging\",\"upstairs\"] else 0\n",
    ")\n",
    "\n",
    "X = df[[\"x\",\"y\",\"z\"]].astype(float)\n",
    "y = df[\"label\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb82b09",
   "metadata": {},
   "source": [
    "part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d5e903",
   "metadata": {},
   "outputs": [],
   "source": [
    "stump = DecisionTreeClassifier(max_depth=1)\n",
    "stump.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train:\", stump.score(X_train, y_train))\n",
    "print(\"Test:\", stump.score(X_test, y_test))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, stump.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b84e4d",
   "metadata": {},
   "source": [
    "part c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7a361b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "T = 20\n",
    "\n",
    "n = X_train.shape[0]\n",
    "weights = np.ones(n) / n\n",
    "\n",
    "alphas = []\n",
    "errors = []\n",
    "stumps = []\n",
    "\n",
    "print(\"=== MANUAL ADABOOST (T = 20) ===\")\n",
    "\n",
    "for t in range(T):\n",
    "\n",
    "    stump = DecisionTreeClassifier(max_depth=1)\n",
    "    stump.fit(X_train, y_train, sample_weight=weights)\n",
    "    stumps.append(stump)\n",
    "    y_pred = stump.predict(X_train)\n",
    "    err = np.sum(weights * (y_pred != y_train))\n",
    "    errors.append(err)\n",
    "    alpha = 0.5 * np.log((1 - err) / (err + 1e-10))\n",
    "    alphas.append(alpha)\n",
    "    misclassified = np.where(y_pred != y_train)[0]\n",
    "\n",
    "    print(f\"\\nIteration {t+1}\")\n",
    "    print(\"Misclassified indices (first 15):\", misclassified[:15])\n",
    "    print(\"Weights of misclassified (first 15):\", weights[misclassified][:15])\n",
    "    print(\"Alpha:\", alpha)\n",
    "\n",
    "    weights = weights * np.exp(alpha * (y_pred != y_train))\n",
    "    weights = weights / np.sum(weights)\n",
    "\n",
    "def ada_predict(X):\n",
    "    final = np.zeros(X.shape[0])\n",
    "    for alpha, stump in zip(alphas, stumps):\n",
    "        pred = stump.predict(X)\n",
    "        pred = np.where(pred == 1, 1, -1) \n",
    "        final += alpha * pred\n",
    "    return np.where(final >= 0, 1, 0)   \n",
    "train_pred = ada_predict(X_train)\n",
    "test_pred = ada_predict(X_test)\n",
    "\n",
    "print(\"\\n=== FINAL RESULTS ===\")\n",
    "print(\"Train Accuracy:\", accuracy_score(y_train, train_pred))\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, test_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, test_pred))\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(errors, marker=\"o\")\n",
    "plt.title(\"Boosting Round vs Weighted Error\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Weighted Error\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(alphas, marker=\"o\")\n",
    "plt.title(\"Boosting Round vs Alpha\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Alpha\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3f82d0",
   "metadata": {},
   "source": [
    "part d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c653ec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=100,\n",
    "    learning_rate=1.0\n",
    ")\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ada.predict(X_test)\n",
    "\n",
    "print(\"Train Acc:\", ada.score(X_train, y_train))\n",
    "print(\"Test Acc:\", ada.score(X_test, y_test))\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
